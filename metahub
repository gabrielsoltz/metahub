#!/usr/bin/env python3

import json
from sys import argv, exit

from helpers import (color, get_logger, get_parser, print_banner, print_table,
                     print_title_line)
from metachecks.metachecks import list_metachecks, run_metachecks, run_tags
from securityhub import SecurityHub


def generate_findings(
    logger, sh_filters, metachecks, mh_filters_checks, metatags, mh_filters_tags, sh_account, sh_role, mh_role
):
    mh_findings = {}
    mh_findings_not_matched_findings = {}
    mh_findings_short = {}
    mh_inventory = []
    mh_statistics = {
        "Title": {},
        "SeverityLabel": {},
        "Workflow": {},
        "RecordState": {},
        "Compliance": {},
        "ProductArn": {},
        "ResourceType": {},
        "AwsAccountId": {},
        "ResourceId": {}
    }
    sh = SecurityHub(logger, sh_account, sh_role)
    sh_findings = sh.get_findings(sh_filters)
    for finding in sh_findings:
        mh_matched = False
        resource_arn, finding_parsed = sh.parse_finding(finding)

        # MetaChecks and MetaTags:
        if metachecks or metatags:
            # If the resource was already matched, we don't run metachecks or metatags again but we show others findings
            if resource_arn in mh_findings:
                mh_matched = True
            if metachecks:
                # We run metachecks only once, if the resource is in mh_findings or mh_findings_not_matched_findings, means it was already evaluated:
                if (
                    not resource_arn in mh_findings
                    and not resource_arn in mh_findings_not_matched_findings
                ):
                    mh_values, mh_checks_matched = run_metachecks(
                        logger, finding, mh_filters_checks, mh_role
                    )
            else:
                mh_checks_matched = True
            if metatags:
                # We run metatags only once:
                if (
                    not resource_arn in mh_findings
                    and not resource_arn in mh_findings_not_matched_findings
                ):
                    mh_tags, mh_tags_matched = run_tags(
                        logger, finding, mh_filters_tags, mh_role
                    )
            else:
                mh_tags_matched = True
            # If both checks are True we show the resource
            if mh_tags_matched and mh_checks_matched:
                mh_matched = True    
        else:
            # If no metachecks and no metachecks, we enforce to True the match so we show the resource:
            mh_matched = True

        # We keep a dict with no matched resources so we don't run MetaChecks again
        if not mh_matched:
            # We add the resource in our output only once:
            if not resource_arn in mh_findings_not_matched_findings:
                mh_findings_not_matched_findings[resource_arn] = {}

        # We show the resouce only if matched MetaChecks (or Metachecks are disabled)
        if mh_matched:

            # STATISTICS (we count by matched finding)

            # Resource ARN
            if not resource_arn in mh_statistics["ResourceId"]:
                mh_statistics["ResourceId"][resource_arn] = 0
            mh_statistics["ResourceId"][resource_arn] += 1

            for key, value in finding_parsed.items():
                # Title
                if not key in mh_statistics["Title"]:
                    mh_statistics["Title"][key] = 0
                mh_statistics["Title"][key] += 1
                # Values
                for v in value:
                    if v == "Workflow" or v == "Compliance":
                        if value[v]:
                            if not value[v]["Status"] in mh_statistics[v]:
                                mh_statistics[v][value[v]["Status"]] = 0
                            mh_statistics[v][value[v]["Status"]] += 1
                            continue
                    if v == "Id":
                        continue
                    if not value[v] in mh_statistics[v]:
                        mh_statistics[v][value[v]] = 0
                    mh_statistics[v][value[v]] += 1
                # AwsAccountId
                if not finding["AwsAccountId"] in mh_statistics["AwsAccountId"]:
                    mh_statistics["AwsAccountId"][finding["AwsAccountId"]] = 0
                mh_statistics["AwsAccountId"][finding["AwsAccountId"]] += 1
                # ResourceType
                if not finding["Resources"][0]["Type"] in mh_statistics["ResourceType"]:
                    mh_statistics["ResourceType"][finding["Resources"][0]["Type"]] = 0
                mh_statistics["ResourceType"][finding["Resources"][0]["Type"]] += 1

            # RESOURCE (we add the resource only once)
            if not resource_arn in mh_findings:
                # Short
                mh_findings[resource_arn] = {"findings": []}
                mh_findings[resource_arn]["AwsAccountId"] = finding["AwsAccountId"]
                mh_findings[resource_arn]["ResourceType"] = finding["Resources"][0]["Type"]
                # Standard
                mh_findings_short[resource_arn] = {"findings": []}
                mh_findings_short[resource_arn]["AwsAccountId"] = finding["AwsAccountId"]
                mh_findings_short[resource_arn]["ResourceType"] = finding["Resources"][0]["Type"]

                # INVENTORY
                mh_inventory.append(resource_arn)

                # METACHECKS:
                if metachecks:
                    # Short
                    mh_findings_short[resource_arn]["metachecks"] = mh_values
                    # Standard
                    mh_findings[resource_arn]["metachecks"] = mh_values

                
                # METATAGS
                if metatags:
                    # Short
                    mh_findings_short[resource_arn]['metatags'] = mh_tags
                    # Standard
                    mh_findings[resource_arn]['metatags'] = mh_tags

            # FINDINGS
            mh_findings_short[resource_arn]["findings"].append(
                list(finding_parsed.keys())[0]
            )
            mh_findings[resource_arn]["findings"].append(finding_parsed)
    
    #Sort Statistics
    for key_to_sort in mh_statistics:
        mh_statistics[key_to_sort] = dict(sorted(mh_statistics[key_to_sort].items(), key=lambda item: item[1], reverse=True))

    return mh_findings, mh_findings_short, sh_findings, mh_inventory, mh_statistics


def update_findings(logger, mh_findings, update, sh_account, sh_role):
    UpdateFilters = {}
    IsNnoteProvided = False
    IsAllowedKeyProvided = False
    for key, value in update.items():
        if key in ("Workflow", "Note"):
            if key == "Workflow":
                WorkflowValues = ("NEW", "NOTIFIED", "RESOLVED", "SUPPRESSED")
                if value not in WorkflowValues:
                    logger.error("Workflow values: " + str(WorkflowValues))
                    exit(1)
                Workflow = {"Workflow": {"Status": value}}
                UpdateFilters.update(Workflow)
                IsAllowedKeyProvided = True
            if key == "Note":
                Note = {"Note": {"Text": value, "UpdatedBy": "MetaHub"}}
                UpdateFilters.update(Note)
                IsNnoteProvided = True
            continue
        logger.error(
            "Unsuported update finding key: " + str(key) + " - Supported Keys: Workflow"
        )
        exit(1)
    if not IsAllowedKeyProvided:
        logger.error(
            'Missing Key to Update in update findings command. Please add Key="This is a value"'
        )
        exit(1)
    if not IsNnoteProvided:
        logger.error(
            'Missing Note in update findings command. Please add Note="This is an example Note"'
        )
        exit(1)
    # Run Update
    sh = SecurityHub(logger, sh_account, sh_role)
    if confirm_choice("Are you sure you want to update all findings?"):
        update_multiple = sh.update_findings(mh_findings, UpdateFilters)
        update_multiple_ProcessedFinding = []
        update_multiple_UnprocessedFindings = []
        for update in update_multiple:
            for ProcessedFinding in update["ProcessedFindings"]:
                logger.info("Updated Finding : " + ProcessedFinding["Id"])
                update_multiple_ProcessedFinding.append(ProcessedFinding)
            for UnprocessedFinding in update["UnprocessedFindings"]:
                logger.error(
                    "Error Updating Finding: "
                    + UnprocessedFinding["FindingIdentifier"]["Id"]
                    + " Error: "
                    + UnprocessedFinding["ErrorMessage"]
                )
                update_multiple_UnprocessedFindings.append(UnprocessedFinding)
        return update_multiple_ProcessedFinding, update_multiple_UnprocessedFindings
    return [], []


def confirm_choice(message):
    """Simple function to confirm the action, returns True or False based on user entry"""
    confirm = input(message + " [c]Confirm or [v]Void: ")
    if confirm != "c" and confirm != "v":
        print("\n Invalid Option. Please Enter a Valid Option.")
        return confirm_choice(message)
    if confirm == "c":
        return True
    return False


def main(args):
    print_banner()
    parser = get_parser()
    args = parser.parse_args(args)
    logger = get_logger(args.log_level)

    def set_sh_filters(sh_filters):
        """Return filters for AWS Security Hub get_findings Call"""
        filters = {}
        for key, values in sh_filters.items():
            if key != "self" and values is not None:
                filters[key] = []
                for value in values:
                    value_to_append = {"Comparison": "EQUALS", "Value": value}
                    filters[key].append(value_to_append)
        return filters

    default_sh_filters = {
        "RecordState": ["ACTIVE"],
        "WorkflowStatus": ["NEW"],
        "ProductName": ["Security Hub"],
    }
    if not args.sh_filters and not args.sh_template:
        sh_filters = default_sh_filters
        sh_filters = set_sh_filters(sh_filters)
    elif args.sh_template:
        import yaml
        from pathlib import Path
        try:
            yaml_to_dict = yaml.safe_load(Path(args.sh_template).read_text())
            dict_values = next(iter(yaml_to_dict.values()))
            sh_filters = dict_values
        except yaml.scanner.ScannerError as err:
            logger.error("SH Template reading error: %s", err)
            exit (0)
        except FileNotFoundError:
            logger.error("SH Template file not found: %s", args.sh_template)
            exit (0)
    else:
        sh_filters = args.sh_filters
        sh_filters = set_sh_filters(sh_filters)

    default_mh_filters_checks = {}
    if not args.mh_filters_checks:
        mh_filters_checks = default_mh_filters_checks
    else:
        mh_filters_checks = args.mh_filters_checks
    for mh_filter_check_key, mh_filter_check_value in mh_filters_checks.items():
        if mh_filters_checks[mh_filter_check_key].lower() == "true":
            mh_filters_checks[mh_filter_check_key] = bool(True)
        elif mh_filters_checks[mh_filter_check_key].lower() == "false":
            mh_filters_checks[mh_filter_check_key] = bool(False)
        else:
            logger.error("MetaHub Filter Only True/False Supported: " + str(mh_filters_checks))
            exit(1)

    default_mh_filters_tags = {}
    if not args.mh_filters_tags:
        mh_filters_tags = default_mh_filters_tags
    else:
        mh_filters_tags = args.mh_filters_tags
    # To Do: Validate

    print_title_line("")
    print_table("SH filters: ", str(sh_filters))
    print_table("SH template: ", str(args.sh_template))
    print_table("Meta Checks: ", str(args.meta_checks))
    print_table("Fltr Checks: ", str(mh_filters_checks))
    print_table("Meta Tags: ", str(args.meta_tags))
    print_table("Fltr Tags: ", str(mh_filters_tags))
    print_table("SH Account: ", str(args.sh_account))
    print_table("SH Role: ", str(args.sh_assume_role))
    print_table("MH Role: ", str(args.mh_assume_role))
    print_table("Output: ", str(args.output))
    print_table("Log Level: ", str(args.log_level))
    print_table("Update: ", str(args.update_findings))

    if args.list_meta_checks:
        print_title_line("List MetaChecks")
        list_metachecks(logger)
        exit(0)

    # Generate Findings
    (
        mh_findings,
        mh_findings_short,
        sh_findings,
        mh_inventory,
        mh_statistics,
    ) = generate_findings(
        logger,
        sh_filters,
        metachecks=args.meta_checks,
        mh_filters_checks=mh_filters_checks,
        metatags=args.meta_tags,
        mh_filters_tags=mh_filters_tags,
        sh_account=args.sh_account,
        sh_role=args.sh_assume_role,
        mh_role=args.mh_assume_role,
    )

    if args.list_findings:
        if mh_findings:
            for out in args.output:
                print_title_line("List Findings: " + out)
                if out == "short":
                    print(json.dumps(mh_findings_short, indent=2))
                if out == "inventory":
                    print(json.dumps(mh_inventory, indent=2))
                if out == "statistics":
                    print(json.dumps(mh_statistics, indent=2))
                if out == "standard":
                    print(json.dumps(mh_findings, indent=2))

    if args.write_json:
        if mh_findings:
            for out in args.output:
                print_title_line("Write Json: " + out)
                if out == "short":
                    with open(out + ".json", "w", encoding="utf-8") as f:
                        json.dump(mh_findings_short, f, indent=2)
                        print_table("File: ", out + ".json")
                if out == "inventory":
                    with open(out + ".json", "w", encoding="utf-8") as f:
                        json.dump(mh_inventory, f, indent=2)
                        print_table("File: ", out + ".json")
                if out == "statistics":
                    with open(out + ".json", "w", encoding="utf-8") as f:
                        json.dump(mh_statistics, f, indent=2)
                        print_table("File: ", out + ".json")
                if out == "standard":
                    with open(out + ".json", "w", encoding="utf-8") as f:
                        json.dump(mh_findings, f, indent=2)
                        print_table("File: ", out + ".json")

    print_title_line("Results")
    print_table("Non-Compliant Resources: ", str(len(mh_findings)))
    print_table("AWS Security Hub Findings: ", str(len(sh_findings)))

    if args.update_findings:
        print_title_line("Update Findings")
        print_table("Findings: ", str(len(sh_findings)))
        print_table("Update: ", str(args.update_findings))
        if not mh_findings:
            print(color["BOLD"] + "Nothing to update..." + color["END"])
            exit(1)
        ProcessedFindings, UnprocessedFindings = update_findings(
            logger,
            mh_findings,
            args.update_findings,
            args.sh_account,
            args.sh_assume_role,
        )
        print_title_line("Results")
        print_table("ProcessedFindings: ", str(len(ProcessedFindings)))
        print_table("UnprocessedFindings: ", str(len(UnprocessedFindings)))


if __name__ == "__main__":
    main(argv[1:])
